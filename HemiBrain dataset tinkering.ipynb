{"cells":[{"cell_type":"code","execution_count":2,"id":"5a160698","metadata":{"id":"5a160698","executionInfo":{"status":"ok","timestamp":1680383125107,"user_tz":240,"elapsed":229,"user":{"displayName":"Zongyu Chen","userId":"17178213289345454720"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"id":"c02d18d7","metadata":{"id":"c02d18d7","executionInfo":{"status":"ok","timestamp":1680383131826,"user_tz":240,"elapsed":4578,"user":{"displayName":"Zongyu Chen","userId":"17178213289345454720"}}},"outputs":[],"source":["import torch\n","import torch.nn.init as init"]},{"cell_type":"code","execution_count":4,"id":"15f6fa81","metadata":{"id":"15f6fa81","outputId":"07b721de-a584-454a-e0a9-0ed927be5d6e","executionInfo":{"status":"ok","timestamp":1680383131827,"user_tz":240,"elapsed":7,"user":{"displayName":"Zongyu Chen","userId":"17178213289345454720"}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'exported-traced-adjacencies': No such file or directory\n"]}],"source":["# hemibrain\n","!ls exported-traced-adjacencies "]},{"cell_type":"code","execution_count":5,"id":"89fc7a3c","metadata":{"id":"89fc7a3c","executionInfo":{"status":"error","timestamp":1680383134318,"user_tz":240,"elapsed":319,"user":{"displayName":"Zongyu Chen","userId":"17178213289345454720"}},"outputId":"b4f522cb-9aa6-456e-c3ff-befdc5c61950","colab":{"base_uri":"https://localhost:8080/","height":360}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4e471f9ae9be>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraced_neurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exported-traced-adjacencies/traced-neurons.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraced_roi_connections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exported-traced-adjacencies/traced-roi-connections.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraced_total_connections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exported-traced-adjacencies/traced-total-connections.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exported-traced-adjacencies/traced-neurons.csv'"]}],"source":["traced_neurons = pd.read_csv('exported-traced-adjacencies/traced-neurons.csv')\n","traced_roi_connections = pd.read_csv('exported-traced-adjacencies/traced-roi-connections.csv')\n","traced_total_connections = pd.read_csv('exported-traced-adjacencies/traced-total-connections.csv')"]},{"cell_type":"code","execution_count":null,"id":"3da0f808","metadata":{"scrolled":true,"id":"3da0f808","outputId":"0fbc7ca1-5070-4dc7-db80-015d0aa4e772"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bodyId</th>\n","      <th>instance</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5813054846</td>\n","      <td>PVM03y_pct(PVM03)_R</td>\n","      <td>PVM03y_pct</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1479492693</td>\n","      <td>AVL13t_pct(AVL13)_R</td>\n","      <td>AVL13t_pct</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5812982999</td>\n","      <td>KCg</td>\n","      <td>KCg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1720300275</td>\n","      <td>AVL04v_d_pct(AVL04)_R</td>\n","      <td>AVL04v_d_pct</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5813060766</td>\n","      <td>PDL14m_a_pct(PDL14)_R</td>\n","      <td>PDL14m_a_pct</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21658</th>\n","      <td>583132200</td>\n","      <td>(ADM01)_L</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21659</th>\n","      <td>5813098080</td>\n","      <td>ADL01os_pct(ADL01)_R</td>\n","      <td>ADL01os_pct</td>\n","    </tr>\n","    <tr>\n","      <th>21660</th>\n","      <td>1948478919</td>\n","      <td>AVL14t_pct(AVL14)_R</td>\n","      <td>AVL14t_pct</td>\n","    </tr>\n","    <tr>\n","      <th>21661</th>\n","      <td>604061479</td>\n","      <td>AVL12j_pct(AVL12)_R</td>\n","      <td>AVL12j_pct</td>\n","    </tr>\n","    <tr>\n","      <th>21662</th>\n","      <td>453794660</td>\n","      <td>ADM04n_d_pct(ADM04)_R</td>\n","      <td>ADM04n_d_pct</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21663 rows × 3 columns</p>\n","</div>"],"text/plain":["           bodyId               instance          type\n","0      5813054846    PVM03y_pct(PVM03)_R    PVM03y_pct\n","1      1479492693    AVL13t_pct(AVL13)_R    AVL13t_pct\n","2      5812982999                    KCg           KCg\n","3      1720300275  AVL04v_d_pct(AVL04)_R  AVL04v_d_pct\n","4      5813060766  PDL14m_a_pct(PDL14)_R  PDL14m_a_pct\n","...           ...                    ...           ...\n","21658   583132200              (ADM01)_L           NaN\n","21659  5813098080   ADL01os_pct(ADL01)_R   ADL01os_pct\n","21660  1948478919    AVL14t_pct(AVL14)_R    AVL14t_pct\n","21661   604061479    AVL12j_pct(AVL12)_R    AVL12j_pct\n","21662   453794660  ADM04n_d_pct(ADM04)_R  ADM04n_d_pct\n","\n","[21663 rows x 3 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["traced_neurons"]},{"cell_type":"code","execution_count":null,"id":"ab512848","metadata":{"id":"ab512848"},"outputs":[],"source":["num_nodes = 21663"]},{"cell_type":"code","execution_count":null,"id":"c2468dfd","metadata":{"id":"c2468dfd"},"outputs":[],"source":["unique_labels = traced_neurons['instance'].unique()"]},{"cell_type":"code","execution_count":null,"id":"01aa38f5","metadata":{"id":"01aa38f5"},"outputs":[],"source":["# assign indexes\n","label_idx_dict = {}\n","for i, label in enumerate(unique_labels):\n","    label_idx_dict[label] = i"]},{"cell_type":"code","execution_count":null,"id":"e609e168","metadata":{"id":"e609e168"},"outputs":[],"source":["labels = [label_idx_dict[label] for label in traced_neurons['instance'].values]"]},{"cell_type":"code","execution_count":null,"id":"e0ba2233","metadata":{"id":"e0ba2233","outputId":"6b8f1daf-2713-4bb0-f7e7-aee43908f57c"},"outputs":[{"name":"stdout","output_type":"stream","text":["6223\n"]}],"source":["# get number of neuron types\n","num_classes = traced_neurons['instance'].nunique()\n","print(num_classes)"]},{"cell_type":"code","execution_count":null,"id":"8ff30170","metadata":{"id":"8ff30170","outputId":"87a50ccd-a94e-4e2b-f494-bb37b4ac13e3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bodyId_pre</th>\n","      <th>bodyId_post</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5813054846</td>\n","      <td>5813020143</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5813054846</td>\n","      <td>2215550458</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5813054846</td>\n","      <td>1448575109</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5813054846</td>\n","      <td>1223388206</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5813054846</td>\n","      <td>1913403687</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3413155</th>\n","      <td>453794660</td>\n","      <td>481070027</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3413156</th>\n","      <td>453794660</td>\n","      <td>423792440</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3413157</th>\n","      <td>453794660</td>\n","      <td>455172836</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3413158</th>\n","      <td>453794660</td>\n","      <td>388975834</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3413159</th>\n","      <td>453794660</td>\n","      <td>767904550</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3413160 rows × 3 columns</p>\n","</div>"],"text/plain":["         bodyId_pre  bodyId_post  weight\n","0        5813054846   5813020143       1\n","1        5813054846   2215550458       1\n","2        5813054846   1448575109       1\n","3        5813054846   1223388206       1\n","4        5813054846   1913403687       1\n","...             ...          ...     ...\n","3413155   453794660    481070027       1\n","3413156   453794660    423792440       2\n","3413157   453794660    455172836       1\n","3413158   453794660    388975834       3\n","3413159   453794660    767904550       1\n","\n","[3413160 rows x 3 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["traced_total_connections"]},{"cell_type":"code","execution_count":null,"id":"eddacc52","metadata":{"id":"eddacc52"},"outputs":[],"source":["# assign indexes to bodyIds\n","bodyIds = traced_total_connections['bodyId_post'].unique()\n","bodyIds = sorted(bodyIds)"]},{"cell_type":"code","execution_count":null,"id":"3e6360f3","metadata":{"id":"3e6360f3"},"outputs":[],"source":["def bodyId_to_idx(bodyId):\n","    return bodyIds.index(bodyId)"]},{"cell_type":"markdown","id":"85184d91","metadata":{"id":"85184d91"},"source":["# Convert to DGL graph object"]},{"cell_type":"code","execution_count":null,"id":"2459e0fb","metadata":{"id":"2459e0fb"},"outputs":[],"source":["import os\n","os.environ['DGLBACKEND'] = 'pytorch'\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import dgl\n","import dgl.data\n","from dgl.utils import expand_as_pair\n","import dgl.function as fn\n","\n","import timeit"]},{"cell_type":"code","execution_count":null,"id":"6abf032f","metadata":{"id":"6abf032f"},"outputs":[],"source":["bodyId_idx_dict = {}\n","for i, bodyId in enumerate(bodyIds):\n","    bodyId_idx_dict[bodyId] = i"]},{"cell_type":"code","execution_count":null,"id":"7e02daa1","metadata":{"id":"7e02daa1","outputId":"812e6127-c4af-4d45-da9f-4cb2e51799c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["time elapsed: 3.984710899999982 s\n"]}],"source":["start = timeit.default_timer()\n","pre_indexes = np.vectorize(bodyId_idx_dict.get)(traced_total_connections['bodyId_pre'].values)\n","end = timeit.default_timer()\n","print(f\"time elapsed: {end - start} s\")\n","# from https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key"]},{"cell_type":"code","execution_count":null,"id":"e90e10f7","metadata":{"id":"e90e10f7","outputId":"101935ab-eaf3-44d1-d9ae-e5e93c828e72"},"outputs":[{"name":"stdout","output_type":"stream","text":["time elapsed: 5.17346520000001 s\n"]}],"source":["start = timeit.default_timer()\n","post_indexes = np.vectorize(bodyId_idx_dict.get)(traced_total_connections['bodyId_post'].values)\n","end = timeit.default_timer()\n","print(f\"time elapsed: {end - start} s\")\n","# from https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key"]},{"cell_type":"code","execution_count":null,"id":"eeeea227","metadata":{"id":"eeeea227","outputId":"b2b0ff2a-6571-4ebb-db37-fcef707627b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["time elapsed: 0.10473259999992024s\n"]}],"source":["start = timeit.default_timer()\n","graph = dgl.graph((pre_indexes, post_indexes), num_nodes=num_nodes)\n","end = timeit.default_timer()\n","print(f\"time elapsed: {end-start}s\")"]},{"cell_type":"code","execution_count":null,"id":"11a831d6","metadata":{"id":"11a831d6","outputId":"fb41b809-8fd5-48a3-963c-0b8f95a2e0d4"},"outputs":[{"data":{"text/plain":["Graph(num_nodes=21663, num_edges=3413160,\n","      ndata_schemes={}\n","      edata_schemes={})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["graph"]},{"cell_type":"markdown","id":"d92b904c","metadata":{"id":"d92b904c"},"source":["### using GCN\n","model from https://discuss.dgl.ai/t/how-could-use-edge-or-node-weight/1310/2"]},{"cell_type":"code","execution_count":null,"id":"35515bf5","metadata":{"id":"35515bf5"},"outputs":[],"source":["e_weights = torch.tensor(traced_total_connections['weight'].values)#.unsqueeze(-1)"]},{"cell_type":"code","execution_count":null,"id":"c9122916","metadata":{"id":"c9122916","outputId":"c1647fd1-8f0a-4fff-addf-f9af3f38fd58"},"outputs":[{"data":{"text/plain":["torch.Size([3413160])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["e_weights.shape"]},{"cell_type":"code","execution_count":null,"id":"4ef64c6f","metadata":{"id":"4ef64c6f"},"outputs":[],"source":["# pylint: disable=W0235\n","class GraphConv(nn.Module):\n","    r\"\"\"\n","    Description\n","    -----------\n","    Graph convolution was introduced in `GCN <https://arxiv.org/abs/1609.02907>`__\n","    and mathematically is defined as follows:\n","    .. math::\n","      h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h_j^{(l)}W^{(l)})\n","    where :math:`\\mathcal{N}(i)` is the set of neighbors of node :math:`i`,\n","    :math:`c_{ij}` is the product of the square root of node degrees\n","    (i.e.,  :math:`c_{ij} = \\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}`),\n","    and :math:`\\sigma` is an activation function.\n","\n","    Parameters\n","    ----------\n","    in_feats : int\n","        Input feature size; i.e, the number of dimensions of :math:`h_j^{(l)}`.\n","    out_feats : int\n","        Output feature size; i.e., the number of dimensions of :math:`h_i^{(l+1)}`.\n","    norm : str, optional\n","        How to apply the normalizer. If is `'right'`, divide the aggregated messages\n","        by each node's in-degrees, which is equivalent to averaging the received messages.\n","        If is `'none'`, no normalization is applied. Default is `'both'`,\n","        where the :math:`c_{ij}` in the paper is applied.\n","    weight : bool, optional\n","        If True, apply a linear layer. Otherwise, aggregating the messages\n","        without a weight matrix.\n","    bias : bool, optional\n","        If True, adds a learnable bias to the output. Default: ``True``.\n","    activation : callable activation function/layer or None, optional\n","        If not None, applies an activation function to the updated node features.\n","        Default: ``None``.\n","    allow_zero_in_degree : bool, optional\n","        If there are 0-in-degree nodes in the graph, output for those nodes will be invalid\n","        since no message will be passed to those nodes. This is harmful for some applications\n","        causing silent performance regression. This module will raise a DGLError if it detects\n","        0-in-degree nodes in input graph. By setting ``True``, it will suppress the check\n","        and let the users handle it by themselves. Default: ``False``.\n","\n","    Attributes\n","    ----------\n","    weight : torch.Tensor\n","        The learnable weight tensor.\n","    bias : torch.Tensor\n","        The learnable bias tensor.\n","\n","    Note\n","    ----\n","    Zero in-degree nodes will lead to invalid output value. This is because no message\n","    will be passed to those nodes, the aggregation function will be appied on empty input.\n","    A common practice to avoid this is to add a self-loop for each node in the graph if\n","    it is homogeneous, which can be achieved by:\n","    >>> g = ... # a DGLGraph\n","    >>> g = dgl.add_self_loop(g)\n","    Calling ``add_self_loop`` will not work for some graphs, for example, heterogeneous graph\n","    since the edge type can not be decided for self_loop edges. Set ``allow_zero_in_degree``\n","    to ``True`` for those cases to unblock the code and handle zere-in-degree nodes manually.\n","    A common practise to handle this is to filter out the nodes with zere-in-degree when use\n","    after conv.\n","\n","    Examples\n","    --------\n","    >>> import dgl\n","    >>> import numpy as np\n","    >>> import torch as th\n","    >>> from dgl.nn import GraphConv\n","    >>> # Case 1: Homogeneous graph\n","    >>> g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n","    >>> g = dgl.add_self_loop(g)\n","    >>> feat = th.ones(6, 10)\n","    >>> conv = GraphConv(10, 2, norm='both', weight=True, bias=True)\n","    >>> res = conv(g, feat)\n","    >>> print(res)\n","    tensor([[ 1.3326, -0.2797],\n","            [ 1.4673, -0.3080],\n","            [ 1.3326, -0.2797],\n","            [ 1.6871, -0.3541],\n","            [ 1.7711, -0.3717],\n","            [ 1.0375, -0.2178]], grad_fn=<AddBackward0>)\n","    >>> # allow_zero_in_degree example\n","    >>> g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n","    >>> conv = GraphConv(10, 2, norm='both', weight=True, bias=True, allow_zero_in_degree=True)\n","    >>> res = conv(g, feat)\n","    >>> print(res)\n","    tensor([[-0.2473, -0.4631],\n","            [-0.3497, -0.6549],\n","            [-0.3497, -0.6549],\n","            [-0.4221, -0.7905],\n","            [-0.3497, -0.6549],\n","            [ 0.0000,  0.0000]], grad_fn=<AddBackward0>)\n","    >>> # Case 2: Unidirectional bipartite graph\n","    >>> u = [0, 1, 0, 0, 1]\n","    >>> v = [0, 1, 2, 3, 2]\n","    >>> g = dgl.bipartite((u, v))\n","    >>> u_fea = th.rand(2, 5)\n","    >>> v_fea = th.rand(4, 5)\n","    >>> conv = GraphConv(5, 2, norm='both', weight=True, bias=True)\n","    >>> res = conv(g, (u_fea, v_fea))\n","    >>> res\n","    tensor([[-0.2994,  0.6106],\n","            [-0.4482,  0.5540],\n","            [-0.5287,  0.8235],\n","            [-0.2994,  0.6106]], grad_fn=<AddBackward0>)\n","    \"\"\"\n","    def __init__(self,\n","                 in_feats,\n","                 out_feats,\n","                 norm='both',\n","                 weight=True,\n","                 bias=True,\n","                 activation=None,\n","                 allow_zero_in_degree=False):\n","        super(GraphConv, self).__init__()\n","        if norm not in ('none', 'both', 'right'):\n","            raise DGLError('Invalid norm value. Must be either \"none\", \"both\" or \"right\".'\n","                           ' But got \"{}\".'.format(norm))\n","        self._in_feats = in_feats\n","        self._out_feats = out_feats\n","        self._norm = norm\n","        self._allow_zero_in_degree = allow_zero_in_degree\n","\n","        if weight:\n","            self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n","        else:\n","            self.register_parameter('weight', None)\n","\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(out_feats))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        self.reset_parameters()\n","\n","        self._activation = activation\n","\n","    def reset_parameters(self):\n","        r\"\"\"\n","        Description\n","        -----------\n","        Reinitialize learnable parameters.\n","\n","        Note\n","        ----\n","        The model parameters are initialized as in the\n","        `original implementation <https://github.com/tkipf/gcn/blob/master/gcn/layers.py>`__\n","        where the weight :math:`W^{(l)}` is initialized using Glorot uniform initialization\n","        and the bias is initialized to be zero.\n","        \"\"\"\n","        if self.weight is not None:\n","            init.xavier_uniform_(self.weight)\n","        if self.bias is not None:\n","            init.zeros_(self.bias)\n","\n","    def set_allow_zero_in_degree(self, set_value):\n","        r\"\"\"\n","        Description\n","        -----------\n","        Set allow_zero_in_degree flag.\n","\n","        Parameters\n","        ----------\n","        set_value : bool\n","            The value to be set to the flag.\n","        \"\"\"\n","        self._allow_zero_in_degree = set_value\n","\n","    def forward(self, graph, feat, eweight, weight=None):\n","        r\"\"\"\n","        Description\n","        -----------\n","        Compute graph convolution.\n","\n","        Parameters\n","        ----------\n","        graph : DGLGraph\n","            The graph.\n","        feat : torch.Tensor or pair of torch.Tensor\n","            If a torch.Tensor is given, it represents the input feature of shape\n","            :math:`(N, D_{in})`\n","            where :math:`D_{in}` is size of input feature, :math:`N` is the number of nodes.\n","            If a pair of torch.Tensor is given, which is the case for bipartite graph, the pair\n","            must contain two tensors of shape :math:`(N_{in}, D_{in_{src}})` and\n","            :math:`(N_{out}, D_{in_{dst}})`.\n","        eweight : torch.Tensor of shape (E, 1)\n","            Edge weights, E for the number of edges.\n","        weight : torch.Tensor, optional\n","            Optional external weight tensor.\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            The output feature\n","\n","        Raises\n","        ------\n","        DGLError\n","            Case 1:\n","            If there are 0-in-degree nodes in the input graph, it will raise DGLError\n","            since no message will be passed to those nodes. This will cause invalid output.\n","            The error can be ignored by setting ``allow_zero_in_degree`` parameter to ``True``.\n","            Case 2:\n","            External weight is provided while at the same time the module\n","            has defined its own weight parameter.\n","\n","        Note\n","        ----\n","        * Input shape: :math:`(N, *, \\text{in_feats})` where * means any number of additional\n","          dimensions, :math:`N` is the number of nodes.\n","        * Output shape: :math:`(N, *, \\text{out_feats})` where all but the last dimension are\n","          the same shape as the input.\n","        * Weight shape: :math:`(\\text{in_feats}, \\text{out_feats})`.\n","        \"\"\"\n","        with graph.local_scope():\n","            if not self._allow_zero_in_degree:\n","                if (graph.in_degrees() == 0).any():\n","                    raise DGLError('There are 0-in-degree nodes in the graph, '\n","                                   'output for those nodes will be invalid. '\n","                                   'This is harmful for some applications, '\n","                                   'causing silent performance regression. '\n","                                   'Adding self-loop on the input graph by '\n","                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n","                                   'the issue. Setting ``allow_zero_in_degree`` '\n","                                   'to be `True` when constructing this module will '\n","                                   'suppress the check and let the code run.')\n","\n","            # (BarclayII) For RGCN on heterogeneous graphs we need to support GCN on bipartite.\n","            feat_src, feat_dst = expand_as_pair(feat, graph)\n","            if self._norm == 'both':\n","                degs = graph.out_degrees().float().clamp(min=1)\n","                norm = torch.pow(degs, -0.5)\n","                shp = norm.shape + (1,) * (feat_src.dim() - 1)\n","                norm = torch.reshape(norm, shp)\n","                feat_src = feat_src * norm\n","\n","            if weight is not None:\n","                if self.weight is not None:\n","                    raise DGLError('External weight is provided while at the same time the'\n","                                   ' module has defined its own weight parameter. Please'\n","                                   ' create the module with flag weight=False.')\n","            else:\n","                weight = self.weight\n","\n","            # Set edge weights\n","            graph.edata['w'] = eweight\n","            if self._in_feats > self._out_feats:\n","                # mult W first to reduce the feature size for aggregation.\n","                if weight is not None:\n","                    feat_src = torch.matmul(feat_src, weight)\n","                graph.srcdata['h'] = feat_src\n","                # Changed from fn.copy_src to fn.u_mul_e\n","                graph.update_all(fn.u_mul_e(lhs_field='h', rhs_field='w', out='m'),\n","                                 fn.sum(msg='m', out='h'))\n","                rst = graph.dstdata['h']\n","            else:\n","                # aggregate first then mult W\n","                graph.srcdata['h'] = feat_src\n","                # Changed from fn.copy_src to fn.u_mul_e\n","                graph.update_all(fn.u_mul_e(lhs_field='h', rhs_field='w', out='m'),\n","                                 fn.sum(msg='m', out='h'))\n","                rst = graph.dstdata['h']\n","                if weight is not None:\n","                    rst = torch.matmul(rst, weight)\n","\n","            if self._norm != 'none':\n","                degs = graph.in_degrees().float().clamp(min=1)\n","                if self._norm == 'both':\n","                    norm = torch.pow(degs, -0.5)\n","                else:\n","                    norm = 1.0 / degs\n","                shp = norm.shape + (1,) * (feat_dst.dim() - 1)\n","                norm = torch.reshape(norm, shp)\n","                rst = rst * norm\n","\n","            if self.bias is not None:\n","                rst = rst + self.bias\n","\n","            if self._activation is not None:\n","                rst = self._activation(rst)\n","\n","            return rst"]},{"cell_type":"code","execution_count":null,"id":"97e17764","metadata":{"id":"97e17764"},"outputs":[],"source":["gnn = GraphConv(in_feats = 2, # in degree and out degree\n","               out_feats = num_classes,\n","               allow_zero_in_degree = True)"]},{"cell_type":"code","execution_count":null,"id":"82e78c5f","metadata":{"id":"82e78c5f"},"outputs":[],"source":["# add additional parameters"]},{"cell_type":"code","execution_count":null,"id":"e98aeb37","metadata":{"id":"e98aeb37"},"outputs":[],"source":["graph.ndata['feat'] = torch.stack([graph.in_degrees(), graph.out_degrees()]).T"]},{"cell_type":"code","execution_count":null,"id":"1cff6546","metadata":{"id":"1cff6546"},"outputs":[],"source":["graph.ndata['train_mask'] = torch.zeros(num_nodes, dtype=bool)"]},{"cell_type":"code","execution_count":null,"id":"96d6b282","metadata":{"id":"96d6b282"},"outputs":[],"source":["graph.ndata['test_mask'] = torch.zeros(num_nodes, dtype=bool)\n","graph.ndata['val_mask'] = torch.zeros(num_nodes, dtype=bool)\n"]},{"cell_type":"code","execution_count":null,"id":"a3a79a28","metadata":{"id":"a3a79a28"},"outputs":[],"source":["graph.ndata['train_mask'][0:15000] = True\n","graph.ndata['val_mask'][15000:16000] = True\n","graph.ndata['test_mask'][16000:] = True"]},{"cell_type":"code","execution_count":null,"id":"44671ac2","metadata":{"id":"44671ac2"},"outputs":[],"source":["graph.ndata['label'] = torch.tensor(labels)"]},{"cell_type":"code","execution_count":null,"id":"22203384","metadata":{"id":"22203384"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d3c6c987","metadata":{"id":"d3c6c987","outputId":"b67c31a4-0caf-43a7-a5cd-0da37b65bcec"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Ben Wu\\.conda\\envs\\gnn\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  assert input.numel() == input.storage().size(), (\n"]},{"name":"stdout","output_type":"stream","text":["In epoch 0, loss: 47.461, train acc: 0.000, val acc: 0.000 (best 0.000), test acc: 0.000 (best 0.000)\n","In epoch 5, loss: 34.969, train acc: 0.002, val acc: 0.003 (best 0.003), test acc: 0.003 (best 0.003)\n","In epoch 10, loss: 26.599, train acc: 0.012, val acc: 0.012 (best 0.012), test acc: 0.011 (best 0.014)\n","In epoch 15, loss: 20.647, train acc: 0.004, val acc: 0.001 (best 0.012), test acc: 0.004 (best 0.014)\n","In epoch 20, loss: 16.095, train acc: 0.002, val acc: 0.003 (best 0.012), test acc: 0.001 (best 0.014)\n"]}],"source":["def train(g, model, lr = 0.001):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    best_val_acc = 0\n","    best_test_acc = 0\n","\n","    features = g.ndata[\"feat\"]\n","    labels = g.ndata[\"label\"]\n","    train_mask = g.ndata[\"train_mask\"]\n","    val_mask = g.ndata[\"val_mask\"]\n","    test_mask = g.ndata[\"test_mask\"]\n","    for e in range(100):\n","        # Forward\n","        logits = model(g, features, e_weights.to(torch.float32))\n","\n","        # Compute prediction\n","        pred = logits.argmax(1)\n","\n","        # Compute loss\n","        # Note that you should only compute the losses of the nodes in the training set.\n","        \n","#         print(logits[train_mask].squeeze().shape)\n","#         print(logits[train_mask].squeeze())\n","#         print(labels[train_mask].shape)\n","#         print(labels[train_mask])\n","        \n","#         loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n","        loss = F.cross_entropy(logits[train_mask].squeeze(0), labels[train_mask])\n","\n","        # Compute accuracy on training/validation/test\n","        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n","        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n","        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n","\n","        # Save the best validation accuracy and the corresponding test accuracy.\n","        if best_val_acc < val_acc:\n","            best_val_acc = val_acc\n","            best_test_acc = test_acc\n","\n","        # Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if e % 5 == 0:\n","            print(\n","                \"In epoch {}, loss: {:.3f}, train acc: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(\n","                    e, loss, train_acc, val_acc, best_val_acc, test_acc, best_test_acc\n","                )\n","            )\n","\n","\n","train(graph, gnn)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}